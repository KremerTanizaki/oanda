{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プログラムの構成\n",
    "#1.事前設定:oandapyのインストール, googlecolabのドライブマウント, setup_fxconn()\n",
    "#2.為替相場から値を取得:fetch_fxvalue()\n",
    "#3.データ成形し、特徴量抽出:calc_feat()\n",
    "#4.モデル学習:train_model()\n",
    "#5.将来の為替変動予測:predict()\n",
    "#6.予測結果をもとに取引の戦略を立てる:build_strategy()\n",
    "#7.取引:transaction_with_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-0799e0ff2841>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-0799e0ff2841>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    $ pip install git+https://github.com/oanda/oandapy.git\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#1.事前設定\n",
    "#oandapyインストール\n",
    "pip install git+https://github.com/oanda/oandapy.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#google collaboration上で、Google ドライブをマウント\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 為替相場から値を取得:fetch_fxvalue()\n",
    "# API接続設定のファイルを読み込む\n",
    "import configparser\n",
    "import oandapy\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "#TODO: 外部から読み込む形にしたい\n",
    "#path_oanda='./drive/My Drive/oandapy' #google colac用\n",
    "path_oanda='..'\n",
    "path_config=path_oanda+'/data/config.txt'\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(path_config)\n",
    "\n",
    "#TODO: グローバル変数にしたくない\n",
    "instrument = config['oanda']['instrument']\n",
    "granularity = config['oanda']['granularity']\n",
    "count = int(config['oanda']['count'])\n",
    "api_key = config['oanda']['api_key']\n",
    "account_id = config['oanda']['account_id']\n",
    "\n",
    "\n",
    "def create_api_fxconn(path_config):\n",
    "# API接続\n",
    "    oanda = oandapy.API(environment=\"practice\", access_token=api_key)\n",
    "    return oanda\n",
    "\n",
    "\n",
    "def iso_jp(iso):\n",
    "#日付の調整する\n",
    "#文字列 -> datetime\n",
    "     date = None\n",
    "     try:\n",
    "         date = datetime.strptime(iso, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "         date = pytz.utc.localize(date).astimezone(pytz.timezone(\"Asia/Tokyo\"))\n",
    "     except ValueError:\n",
    "         try:\n",
    "             date = datetime.strptime(iso, '%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "             date = dt.astimezone(pytz.timezone(\"Asia/Tokyo\"))\n",
    "         except ValueError:\n",
    "             pass\n",
    "     return date\n",
    "\n",
    "  \n",
    "def create_df_fxvalue_latesthistory_rawdata(oanda):\n",
    "#生データのdfを生成\n",
    "    instrument, granularity, count = (config['oanda']['instrument'], \n",
    "                                      config['oanda']['granularity'], \n",
    "                                      int(config['oanda']['count']))\n",
    "    json_response = oanda.get_history(instrument=instrument, \n",
    "                                      granularity=granularity, \n",
    "                                      count=count)\n",
    "    df_response = pd.DataFrame(json_response[\"candles\"])\n",
    "    df_response[\"time\"] = df_response[\"time\"].apply(lambda x: iso_jp(x))\n",
    "    return df_response\n",
    "\n",
    "#-----------------main-----------------------------\n",
    "\n",
    "def fetch_fxvalue(path_config):\n",
    "#2のメイン関数, 為替の値を取得\n",
    "    instrument, granularity, count = (config['oanda']['instrument'], \n",
    "                                      config['oanda']['granularity'], \n",
    "                                      int(config['oanda']['count']))\n",
    "    oanda = create_api_fxconn(path_config=path_config)\n",
    "    df_fxvalue_latesthistory_rawdata = create_df_fxvalue_latesthistory_rawdata(oanda)\n",
    "    return df_fxvalue_latesthistory_rawdata \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>closeAsk</th>\n",
       "      <th>closeBid</th>\n",
       "      <th>complete</th>\n",
       "      <th>highAsk</th>\n",
       "      <th>highBid</th>\n",
       "      <th>lowAsk</th>\n",
       "      <th>lowBid</th>\n",
       "      <th>openAsk</th>\n",
       "      <th>openBid</th>\n",
       "      <th>time</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109.984</td>\n",
       "      <td>109.971</td>\n",
       "      <td>True</td>\n",
       "      <td>109.993</td>\n",
       "      <td>109.983</td>\n",
       "      <td>109.983</td>\n",
       "      <td>109.971</td>\n",
       "      <td>109.983</td>\n",
       "      <td>109.971</td>\n",
       "      <td>2020-01-21 18:15:00+09:00</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109.985</td>\n",
       "      <td>109.974</td>\n",
       "      <td>True</td>\n",
       "      <td>109.989</td>\n",
       "      <td>109.977</td>\n",
       "      <td>109.984</td>\n",
       "      <td>109.972</td>\n",
       "      <td>109.985</td>\n",
       "      <td>109.973</td>\n",
       "      <td>2020-01-21 18:16:00+09:00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109.981</td>\n",
       "      <td>109.968</td>\n",
       "      <td>True</td>\n",
       "      <td>109.984</td>\n",
       "      <td>109.972</td>\n",
       "      <td>109.972</td>\n",
       "      <td>109.960</td>\n",
       "      <td>109.984</td>\n",
       "      <td>109.972</td>\n",
       "      <td>2020-01-21 18:17:00+09:00</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109.987</td>\n",
       "      <td>109.975</td>\n",
       "      <td>True</td>\n",
       "      <td>109.991</td>\n",
       "      <td>109.979</td>\n",
       "      <td>109.978</td>\n",
       "      <td>109.966</td>\n",
       "      <td>109.982</td>\n",
       "      <td>109.970</td>\n",
       "      <td>2020-01-21 18:18:00+09:00</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109.979</td>\n",
       "      <td>109.967</td>\n",
       "      <td>True</td>\n",
       "      <td>109.990</td>\n",
       "      <td>109.977</td>\n",
       "      <td>109.977</td>\n",
       "      <td>109.966</td>\n",
       "      <td>109.985</td>\n",
       "      <td>109.974</td>\n",
       "      <td>2020-01-21 18:19:00+09:00</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   closeAsk  closeBid  complete  highAsk  highBid   lowAsk   lowBid  openAsk  \\\n",
       "0   109.984   109.971      True  109.993  109.983  109.983  109.971  109.983   \n",
       "1   109.985   109.974      True  109.989  109.977  109.984  109.972  109.985   \n",
       "2   109.981   109.968      True  109.984  109.972  109.972  109.960  109.984   \n",
       "3   109.987   109.975      True  109.991  109.979  109.978  109.966  109.982   \n",
       "4   109.979   109.967      True  109.990  109.977  109.977  109.966  109.985   \n",
       "\n",
       "   openBid                      time  volume  \n",
       "0  109.971 2020-01-21 18:15:00+09:00      34  \n",
       "1  109.973 2020-01-21 18:16:00+09:00      41  \n",
       "2  109.972 2020-01-21 18:17:00+09:00      51  \n",
       "3  109.970 2020-01-21 18:18:00+09:00      47  \n",
       "4  109.974 2020-01-21 18:19:00+09:00      31  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 テスト\n",
    "path_oanda='..'\n",
    "path_config=path_oanda+'/data/config.txt'\n",
    "tmp = fetch_fxvalue(path_config)\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 特徴量抽出:feat_calc()\n",
    "# API接続設定のファイルを読み込む\n",
    "\n",
    "def data_maker(data, window_len):\n",
    "    data_lstm_in=[]\n",
    "    if len(data)==window_len:\n",
    "        temp = data[:window_len].copy()\n",
    "        temp = temp / temp.iloc[0] - 1\n",
    "        data_lstm_in.append(temp)\n",
    "    for i in range(len(data) - window_len):\n",
    "        temp = data[i:(i + window_len)].copy()\n",
    "        temp = temp / temp.iloc[0] - 1\n",
    "        data_lstm_in.append(temp)\n",
    "    return data_lstm_in\n",
    "\n",
    "\n",
    "def pd_to_np(data_lstm_in):\n",
    "#うんこみたいな関数すぎる、変えたい\n",
    "#もともとdf？listになってるんやけど\n",
    "    data_lstm_in = [np.array(data_lstm_input) for data_lstm_input in data_lstm_in]  #array のリスト\n",
    "    data_lstm_in = np.array(data_lstm_in) #np.array\n",
    "    return data_lstm_in\n",
    "\n",
    "\n",
    "def extract_feature(df_rawdata, ratio_num_traindata):\n",
    "#特徴量抽出->ここをいじります\n",
    "#ratio_num_traindataは訓練データと検証用データの分割比\n",
    "#TODO: ratio_num_traindataは引数で与えたい\n",
    "\n",
    "    #1. 特徴量算出に必要なカラムを設定\n",
    "    df = df_rawdata[['time', 'openAsk']]\n",
    "    df.columns = ['time', 'open']\n",
    "\n",
    "    #2. 予測に使うデータ数を設定\n",
    "    window_len = 10\n",
    "    #3. 訓練データと検証用データを所定の割合で分割\n",
    "    #TODO: ごちゃごちゃしているので、書き換えたい\n",
    "    train, test = df[df.index < int(len(df)*ratio_num_traindata)], \\\n",
    "                    df[df.index >= int(len(df)*ratio_num_traindata)]\n",
    "    latest = test[:window_len]\n",
    "    del train['time']\n",
    "    del test['time']\n",
    "    del latest['time']\n",
    "    length = len(test)- window_len\n",
    "    \n",
    "    #モデル入力、モデル出力用にデータ成形\n",
    "    ##ここを直して、特徴量抽出のアルゴリズム考える\n",
    "    #TODO: data_makerとかpd_to_npとかいう意味わからん関数書き換えたい\n",
    "    #TODO: latestがよくわからん\n",
    "    train_lstm_in = data_maker(train, window_len)\n",
    "    lstm_train_out = (train['open'][window_len:].values / train['open'][:-window_len].values)-1\n",
    "    test_lstm_in = data_maker(test, window_len)\n",
    "    lstm_test_out = (test['open'][window_len:].values / test['open'][:-window_len].values)-1\n",
    "    latest_lstm_in = data_maker(latest, window_len)\n",
    "    train_lstm_in = pd_to_np(train_lstm_in)\n",
    "    test_lstm_in = pd_to_np(test_lstm_in)\n",
    "    latest_lstm_in = pd_to_np(latest_lstm_in)\n",
    "    \n",
    "    #入出力の名前とかが意味わからなかったので、dictで管理してる\n",
    "    X_dict = {'train':train_lstm_in, 'test':test_lstm_in, 'latest':latest_lstm_in}\n",
    "    y_dict = {'train':lstm_train_out, 'test':lstm_test_out}\n",
    "\n",
    "    return X_dict, y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3テスト\n",
    "X_dict, y_dict = extract_feature(tmp, ratio_num_traindata=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0126 14:28:15.028591 18344 deprecation_wrapper.py:119] From c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0126 14:28:16.147869 18344 deprecation_wrapper.py:119] From c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0126 14:28:16.441787 18344 deprecation_wrapper.py:119] From c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0126 14:28:17.533325 18344 deprecation_wrapper.py:119] From c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0126 14:28:17.562794 18344 deprecation.py:506] From c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0126 14:28:17.641747 18344 deprecation_wrapper.py:119] From c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0126 14:28:18.690308 18344 deprecation.py:323] From c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0126 14:28:20.294610 18344 deprecation_wrapper.py:119] From c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-4045c1bc50d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#TODO ネットワークの設定を、別途configファイルかargs.parserで引数として外部設定できるようにする\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneurons\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# #未来の値\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#4 モデル学習: train_model()\n",
    "#TODO なんもやってない\n",
    "\n",
    "\n",
    "def build_model(inputs, output_size, neurons, activ_func=\"linear\",\n",
    "                dropout=0.25, loss=\"mae\", optimizer=\"adam\"):\n",
    "# モデル設定->ここを工夫\n",
    "    model = Sequential()\n",
    " \n",
    "    model.add(LSTM(neurons, input_shape=(inputs.shape[1], inputs.shape[2])))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units=output_size))\n",
    "    model.add(Activation(activ_func))\n",
    " \n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "#TODO: ランダムシードの設定->文頭に入れるべき\n",
    "np.random.seed(202)\n",
    " \n",
    "# 初期モデルの構築\n",
    "X_train, y_train = X_dict['train'], y_dict['train']\n",
    "#TODO LSTMのセルの数をneuronsという名前から変更すべき\n",
    "#TODO ネットワークの設定を、別途configファイルかargs.parserで引数として外部設定できるようにする\n",
    "model = build_model(X_train, output_size=1, neurons = 20)\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=1, verbose=2, shuffle=True)\n",
    "\n",
    "# #未来の値\n",
    "#TODO: 何も変えていない\n",
    "# empty = []\n",
    "# future_array = np.array(empty)\n",
    "# for i in range(length):\n",
    "#     pred = (((np.transpose(yen_model.predict(latest_lstm_in))+1) * latest['open'].values[0])[0])[0]\n",
    "#     future_array= np.append(future_array,pred)\n",
    "#     data ={'open':[pred]}\n",
    "#     df1 = pd.DataFrame(data)\n",
    "#     latest =pd.concat([latest,df1],axis=0)\n",
    "#     latest.index = range(0,window_len+1)\n",
    "#     latest = latest.drop(0,axis=0)\n",
    "#     latest_lstm_in =pd_to_np(latest_lstm_in)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4テスト\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import oandapy\n",
    "import configparser\n",
    "import pytz\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "#main\n",
    "def main():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
